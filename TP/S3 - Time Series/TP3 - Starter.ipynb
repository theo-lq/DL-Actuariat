{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a70a426b",
      "metadata": {},
      "source": [
        "# TP3 - Prédiction de prix en finance de marché\n",
        "\n",
        "Dans ce notebook, nous allons implémenter plusieurs variantes de réseaux de neurones récurrents pour prédire le prix d'une action. \n",
        "\n",
        "\n",
        "## Préparation\n",
        "\n",
        "Commençons par charger les données et les visualiser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d350101c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "def get_price(tickers, period=\"5y\"):\n",
        "    prices = yf.download(tickers, period=period, auto_adjust=True, progress=False)[\"Close\"]\n",
        "    if prices.empty:\n",
        "        raise ValueError(\"No data returned\")\n",
        "    prices = prices.dropna()\n",
        "    prices.index.name = \"date\"\n",
        "\n",
        "    return prices\n",
        "\n",
        "\n",
        "tickers = [\"TSM\", \"NVDA\", \"META\"]\n",
        "df = get_price(tickers=tickers, period=\"5y\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "711f566d",
      "metadata": {},
      "source": [
        "Visualisons les différents séries :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d99a7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set_style(style=\"whitegrid\")\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "for index, ticker in enumerate(tickers):\n",
        "    y = df[ticker]\n",
        "\n",
        "    plt.subplot(1, len(tickers), index+1)\n",
        "    plt.plot(y, c=sns.color_palette()[0])\n",
        "    plt.title(ticker)\n",
        "    plt.ylabel(\"Price\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cce1ae5",
      "metadata": {
        "id": "3cce1ae5"
      },
      "source": [
        "## Baselines\n",
        "\n",
        "Avant de s'attaquer aux réseaux de neurones, on se propose deux baselines *naïves* :\n",
        "- Prédire le prix de la veille\n",
        "- Faire une moyenne glissante sur 7 jours\n",
        "\n",
        "Nous mesurerons la performance à l'aide de la RMSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce2c6450",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import root_mean_squared_error as RMSE\n",
        "\n",
        "train_size = 0.8\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "for index, ticker in enumerate(tickers):\n",
        "    y = df[ticker]\n",
        "    split = int(train_size * len(y))\n",
        "    y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
        "\n",
        "    y_pred_lag1 = y_test.shift(1)\n",
        "    y_pred_lag1.iloc[0] = y_train.iloc[-1]\n",
        "\n",
        "    history = pd.concat([y_train, y_test])\n",
        "    y_pred_roll7 = history.shift(1).rolling(7).mean().iloc[len(y_train):]\n",
        "\n",
        "    rmse_lag = RMSE(y_test, y_pred_lag1)\n",
        "    rmse_roll = RMSE(y_test, y_pred_roll7)\n",
        "\n",
        "\n",
        "\n",
        "    plt.subplot(1, len(tickers), index+1)\n",
        "    plt.plot(y_test, alpha=0.8, label=\"True\", lw=2)\n",
        "    plt.plot(y_pred_lag1, alpha=0.8, label=f\"Lag-1 (RMSE={rmse_lag:.2f})\")\n",
        "    plt.plot(y_pred_roll7, alpha=0.8, label=f\"Roll7 (RMSE={rmse_roll:.2f})\")\n",
        "    plt.title(f\"{ticker} (mean: {np.mean(y_test):.2f})\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec655bfc",
      "metadata": {
        "id": "ec655bfc"
      },
      "source": [
        "Nous avons déjà des performances très acceptables ! Voyons si un réseau de neurones peut faire mieux.\n",
        "\n",
        "## Réseau de neurones récurrents *simple*\n",
        "\n",
        "On commence par un réseau de neurones récurrents simple, nous traiterons GRU, LSTM et convolutionnel plus tard. Pour le moment, nous allons prédire le prix d'une action en utilisant uniquement les précédents prix de l'action.\n",
        "\n",
        "### Préparation\n",
        "\n",
        "Pour obtenir un dataset d'entraînement et de tests, nous devons :\n",
        "1. Découper le dataset actuel en respectant la chronologie des données\n",
        "2. Normaliser les données : à la fois les features et la cible !\n",
        "\n",
        "Puisque nous souhaitons visualiser les performances de prédiction, nous devons garder en tête que les prédictions devrons être *re-scalées* avec la méthode [`inverse_transform`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.inverse_transform) de la classe [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "671fb1ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def get_dataset(df, ticker, window_size, train_ratio=0.8):\n",
        "    y = df[ticker].values.reshape(-1, 1)\n",
        "\n",
        "    X, Y = [], []\n",
        "    for i in range(window_size, len(y)):\n",
        "        X.append(y[i-window_size:i])\n",
        "        Y.append(y[i])\n",
        "\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "\n",
        "    split = int(train_ratio * len(X))\n",
        "    X_train, X_test = X[:split], X[split:]\n",
        "    y_train, y_test = Y[:split], Y[split:]\n",
        "\n",
        "    X_scaler = StandardScaler()\n",
        "    y_scaler = StandardScaler()\n",
        "\n",
        "    X_train = X_scaler.fit_transform(X_train.reshape(-1, 1)).reshape(X_train.shape)\n",
        "    X_test = X_scaler.transform(X_test.reshape(-1, 1)).reshape(X_test.shape)\n",
        "\n",
        "    y_train = y_scaler.fit_transform(y_train)\n",
        "    y_test = y_scaler.transform(y_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, y_scaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b5b405c",
      "metadata": {},
      "source": [
        "### Modélisation\n",
        "\n",
        "On se propose de définir un modèle avec 64 neurones dans une couche [`SimpleRNN`](https://keras.io/api/layers/recurrent_layers/simple_rnn/).\n",
        "\n",
        "**Consigne** : Définir le modèle souhaité, puis entraîner le modèle sur l'action NVDA (Nvidia) avec une fenêtre glissante de taille 10 (on prendra 30 époques et un batch size de 32). Puis sauvegarder les prédictions du modèle dans un vector `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "851420c9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "993a5e79",
      "metadata": {},
      "source": [
        "On souhaite visualiser la qualité de la prédiction ainsi que la performance métrique du modèle.\n",
        "\n",
        "**Consigne** : Réaliser un graphique comparant le véritable prix de l'action et la prédiction du modèle, en affichant la RMSE du modèle ainsi que la moyenne des prix de l'action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3219a0b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "22a38c20",
      "metadata": {},
      "source": [
        "Il semblerait que le modèle soit *en retard* par rapport aux prix. Cependant les tendances semblent correctes au début, mais de plus en plus éloignées au fur et à mesure du temps.\n",
        "Il est possible que ça soit dû à un entraînement trop court du modèle. Vérifions-le.\n",
        "\n",
        "**Consigne** : Produire un graphique similaire en affichant quatres courbes :\n",
        "1. Le prix de l'action\n",
        "2. La prédiction du modèle après 10 époques d'entraînement\n",
        "3. La prédiction du modèle après 30 époques d'entraînement\n",
        "4. La prédiction du modèle après 50 époques d'entraînement\n",
        "\n",
        "Pour éviter d'entraîner plusieurs modèles différents, on peut réentraîner un modèle pour un nombre d'époques spécifique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7f97c4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "ticker = \"NVDA\"\n",
        "window_size = 10\n",
        "\n",
        "X_train, X_test, y_train, y_test, y_scaler = get_dataset(df, ticker, window_size)\n",
        "\n",
        "model = Sequential([\n",
        "        layers.Input(shape=(window_size, 1)),\n",
        "        layers.SimpleRNN(units=64),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "model.compile(optimizer=Adam(1e-3), loss=\"mse\")\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "y_pred_10 = model.predict(X_test)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
        "y_pred_30 = model.predict(X_test)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
        "y_pred_50 = model.predict(X_test)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(y_scaler.inverse_transform(y_test), label=\"True\", lw=2)\n",
        "plt.plot(y_scaler.inverse_transform(y_pred_10), label=f\"10 epochs (RMSE: {RMSE(y_scaler.inverse_transform(y_test), y_scaler.inverse_transform(y_pred_10)):.2f})\", alpha=0.6)\n",
        "plt.plot(y_scaler.inverse_transform(y_pred_30), label=f\"30 epochs (RMSE: {RMSE(y_scaler.inverse_transform(y_test), y_scaler.inverse_transform(y_pred_30)):.2f})\", alpha=0.6)\n",
        "plt.plot(y_scaler.inverse_transform(y_pred_50), label=f\"50 epochs (RMSE: {RMSE(y_scaler.inverse_transform(y_test), y_scaler.inverse_transform(y_pred_50)):.2f})\", alpha=0.6)\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(f\"{ticker} (mean: {np.mean(y_scaler.inverse_transform(y_test)):.2f})\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5495c67",
      "metadata": {},
      "source": [
        "Effectivement, un entraînement plus long permet d'être plus précis sur les dates les plus lointaines de la fin de l'entraînement.\n",
        "\n",
        "Maintenant que nous avons réussi à prédire le prix d'une action avec un type de couche récurrente, attaquons-nous aux autres actions avec l'ensemble des types de couches.\n",
        "\n",
        "## Comparaisons des différentes couches\n",
        "\n",
        "Nous allons utiliser les couches [`SimpleRNN`](https://keras.io/api/layers/recurrent_layers/simple_rnn/), [`GRU`](https://keras.io/api/layers/recurrent_layers/gru/), [`LSTM`](https://keras.io/api/layers/recurrent_layers/lstm/) et [`Conv1D`](https://keras.io/api/layers/convolution_layers/conv1d/).\n",
        "A part la couche de convolution, les autres couches peuvent être interchangées dans la définition d'un modèle. Exploitant cela, nous proposons la fonction suivante pour obtenir un modèle compilé :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc47787",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model(layer, window_size, learning_rate=1e-3):\n",
        "    if layer == layers.Conv1D:\n",
        "        model = Sequential([\n",
        "            layers.Input(shape=(window_size, 1)),\n",
        "            layers.Conv1D(64, kernel_size=3, activation=\"relu\"),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(1)\n",
        "        ])\n",
        "    else:\n",
        "        model = Sequential([\n",
        "            layers.Input(shape=(window_size, 1)),\n",
        "            layer(64),\n",
        "            layers.Dense(1)\n",
        "        ])\n",
        "    model.compile(optimizer=Adam(learning_rate), loss=\"mse\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d02a011",
      "metadata": {},
      "source": [
        "**Consigne** : A partir des éléments décrit précédemment, produire un graphique où pour les trois actions sont affichés les performances de chaque type de couche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34452631",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "Hrh3HR7F-5KD",
      "metadata": {
        "id": "Hrh3HR7F-5KD"
      },
      "source": [
        "## Predict with other features\n",
        "\n",
        "Jusqu'ici nous n'avons utilisé que les prix précédents, et si nous utilisions les prix des autres actions aussi ?\n",
        "\n",
        "**Consigne** : Adapter la fonction `get_dataset` en ajoutant un paramètre *features* qui correspond à une liste de chaîne de caractère représentant les noms des actions (autre que celle d'intérêt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "957ff88a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cee55200",
      "metadata": {},
      "source": [
        "**Consigne** : Adapter la fonction `get_model` pour prendre en compte le nombre de features total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f75ed9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b2e401f0",
      "metadata": {},
      "source": [
        "**Consigne** : A partir des éléments décrit précédemment, produire un graphique où pour les trois actions sont affichés les performances de chaque type de couche. Cette fois en utilisant l'ensemble des informations disponibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9944e52",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
